# Natural language processing with disaster tweets

The notebook performing data cleaning and analysis using a pretrained RoBERTa model can be seen [here](https://github.com/Orenjonas/natural_language_processing_with_disaster_tweets/blob/main/NLP_disaster_tweets_using_torch_RoBERTa.ipynb).

## Purpose
The purpose of this project is to learn the basics of implementing machine learning algorithms for natural
language processing, and catching up on the state of the art in the field.

The data is provided from [this kaggle competition](https://www.kaggle.com/c/nlp-getting-started),
where the goal is to predict which tweets relate to a real disaster.


## Things to try
- Use "location" and "keyword" in analysis?
- Inspect incorrectly classified tweets
- Add spelling corrections
- Add estimated sentiment of tweet to the data
